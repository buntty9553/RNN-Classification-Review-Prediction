{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04db7fef",
   "metadata": {},
   "source": [
    "# Word Embedding:\n",
    "\n",
    "- üëâ Word Embedding means converting words into numbers (vectors) in such a way that similar words have similar meanings and thus similar vector values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35bd0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b72f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences \n",
    "sent = ['the glass of milk',\n",
    "        'the glass of juice',\n",
    "        'the cup of tea',\n",
    "        'I am a good boy',\n",
    "        'I am a good developer',\n",
    "        'understand the meaning of words',\n",
    "        'your videos are good'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce84b27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de840090",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the vocabulary size\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b9dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6853, 4270, 3409, 700],\n",
       " [6853, 4270, 3409, 7331],\n",
       " [6853, 8941, 3409, 216],\n",
       " [8258, 8394, 1235, 3889, 7772],\n",
       " [8258, 8394, 1235, 3889, 809],\n",
       " [7956, 6853, 4997, 3409, 4239],\n",
       " [4561, 1067, 5763, 3889]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One Hot Representation for every word\n",
    "one_hot_repr = [one_hot(words,voc_size) for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d1a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Embedding representaion \n",
    "from tensorflow.keras.layers import Embedding\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e794f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661599c6",
   "metadata": {},
   "source": [
    "## pad_sequence:\n",
    "üëâ In simple words:\n",
    "pad_sequences() is used to make all input sequences the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b21b751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6853, 4270, 3409, 700],\n",
       " [6853, 4270, 3409, 7331],\n",
       " [6853, 8941, 3409, 216],\n",
       " [8258, 8394, 1235, 3889, 7772],\n",
       " [8258, 8394, 1235, 3889, 809],\n",
       " [7956, 6853, 4997, 3409, 4239],\n",
       " [4561, 1067, 5763, 3889]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffce65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 6853, 4270, 3409,  700],\n",
       "       [   0,    0,    0,    0, 6853, 4270, 3409, 7331],\n",
       "       [   0,    0,    0,    0, 6853, 8941, 3409,  216],\n",
       "       [   0,    0,    0, 8258, 8394, 1235, 3889, 7772],\n",
       "       [   0,    0,    0, 8258, 8394, 1235, 3889,  809],\n",
       "       [   0,    0,    0, 7956, 6853, 4997, 3409, 4239],\n",
       "       [   0,    0,    0,    0, 4561, 1067, 5763, 3889]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pad_sequence\n",
    "sent_len = 8\n",
    "embedded_docs = pad_sequences(one_hot_repr,padding='pre',maxlen=sent_len)\n",
    "embedded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd0e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Representation\n",
    "dim = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "648a1401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\PROJECTS\\Deep Learning\\ANN & RNN\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\PROJECTS\\Deep Learning\\ANN & RNN\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_len))\n",
    "model.compile('adam','mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1643526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100000 (390.62 KB)\n",
      "Trainable params: 100000 (390.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a03045",
   "metadata": {},
   "source": [
    "# Summary :\n",
    "\n",
    "| Step | Purpose                         | Function Used             |\n",
    "| ---- | ------------------------------- | ------------------------- |\n",
    "| 1Ô∏è‚É£  | Collect sentences               | ‚Äî                         |\n",
    "| 2Ô∏è‚É£  | Define vocabulary               | ‚Äî                         |\n",
    "| 3Ô∏è‚É£  | Convert words ‚Üí integers        | `one_hot()`               |\n",
    "| 4Ô∏è‚É£  | Equalize sentence length        | `pad_sequences()`         |\n",
    "| 5Ô∏è‚É£  | Create embedding representation | `Embedding()`             |\n",
    "| 6Ô∏è‚É£  | Feed padded sentences           | `model(padded_sentences)` |\n",
    "| 7Ô∏è‚É£  | (Optional) View learned vectors | `.get_weights()`          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8f795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
